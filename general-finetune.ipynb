{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "from datasets import Dataset, load_dataset, interleave_datasets\n",
    "from peft import get_peft_model, LoraConfig, TaskType, PeftModel\n",
    "from transformers import Trainer, TrainingArguments, AutoTokenizer, DataCollatorForLanguageModeling\n",
    "from transformers.models.llama.modeling_llama import LlamaForCausalLM\n",
    "\n",
    "from evals import evaluate\n",
    "\n",
    "assert torch.cuda.is_available(), \"CUDA not available\"\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "MAX_LENGTH = 512\n",
    "\n",
    "model_id = \"meta-llama/Llama-3.2-1B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adaptllm_path(base_path: Path) -> Path:\n",
    "    with open(base_path / \"refs\" / \"main\", \"r\") as f_in:\n",
    "        snapshot_ref = f_in.readline()\n",
    "    return base_path / \"snapshots\" / snapshot_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load_dataset causes an error, load directly from cached snapshot files\n",
    "hub_basepath = Path(r\"C:\\Users\\samba\\.cache\\huggingface\\hub\")\n",
    "dataset_cache_path = Path(r\"D:/datasets/general-3-tasks\")\n",
    "\n",
    "paths = {\n",
    "    \"FPB\": get_adaptllm_path(hub_basepath / \"datasets--AdaptLLM--FPB\"),\n",
    "    \"Headline\": get_adaptllm_path(hub_basepath / \"datasets--AdaptLLM--Headline\"),\n",
    "    \"Topics\": hub_basepath / r\"datasets--Sujet--TopicClassification\"\n",
    "}\n",
    "\n",
    "names_mapping = {\n",
    "    \"FPB\": None,\n",
    "    \"Headline\": [\"idx\", \"text\", \"question\", \"label\", \"subidx\"],\n",
    "    \"Topics\": [\"label\", \"text\"]\n",
    "}\n",
    "\n",
    "columns = {\n",
    "    \"FPB\": [\"text\", \"label\"],\n",
    "    \"Headline\": [\"idx\", \"text\", \"question\", \"label\", \"subidx\"],\n",
    "    \"Topics\": [\"label\", \"text\"]\n",
    "}\n",
    "\n",
    "del_mapping = {\n",
    "    \"FPB\": \"\\t\",\n",
    "    \"Headline\": \"\\t\",\n",
    "    \"Topics\": None ## regular comma-delimiter'd csv\n",
    "}\n",
    "\n",
    "\n",
    "topics = ['Analyst Update', 'Fed | Central Banks', 'Company | Product News', 'Treasuries | Corporate Debt', 'Dividend', 'Earnings', 'Energy | Oil', 'Financials', 'Currencies', 'General News | Opinion', 'Gold | Metals | Materials', 'IPO', 'Legal | Regulation', 'M&A | Investments', 'Macro', 'Markets', 'Politics', 'Personnel Change', 'Stock Commentary', 'Stock Movement']\n",
    "topic_options = \"\\n\".join([f\"{i} - {t}\" for i, t in enumerate(topics)])\n",
    "prompt_templates = {\n",
    "    \"FPB\": \"{0}\\nQuestion: what is the sentiment?\\nOptions:\\n- Positive\\n- Negative\\n- Neutral\",\n",
    "    \"Headline\": \"Headline: \\\"{0}\\\" Now answer this question: {1}\",\n",
    "    \"Topics\": \"{0}\\nNow classify the topic\\nOptions 0-19:\\n\" + f\"{topic_options} \",\n",
    "}\n",
    "\n",
    "prompt_args = {\n",
    "    \"FPB\": [\"text\"],\n",
    "    \"Headline\": [\"text\", \"question\"],\n",
    "    \"Topics\": [\"text\"],\n",
    "}\n",
    "\n",
    "id2labels = {\n",
    "    \"FPB\": {\"neutral\": \" Neutral\", \"positive\": \" Positive\", \"negative\": \" Negative\"},\n",
    "    \"Headline\": {0: \" No\", 1: \" Yes\"},\n",
    "    \"Topics\": {i: str(i) for i in range(20)},\n",
    "}\n",
    "\n",
    "token_list_raw = [v for task in id2labels.values() for v in task.values()]\n",
    "token_list = [tokenizer.encode(tok, add_special_tokens=False)[0] for tok in token_list_raw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_preprocess_causal(dataset_id: str, example: dict):\n",
    "    # Create prompt and target text\n",
    "    args = [example[key] for key in prompt_args[dataset_id]]\n",
    "    prompt = prompt_templates[dataset_id].format(*args)\n",
    "\n",
    "    target = id2labels[dataset_id][example[\"label\"]]\n",
    "    full_text = prompt + target\n",
    "\n",
    "    # tokenize text\n",
    "    tokenized = tokenizer(full_text,\n",
    "                          truncation=True,\n",
    "                          padding=\"max_length\",\n",
    "                          max_length=MAX_LENGTH)\n",
    "    \n",
    "    # add padding tokens\n",
    "    prompt_tokenized = tokenizer(prompt,\n",
    "                              truncation=True,\n",
    "                              max_length=MAX_LENGTH)\n",
    "    prompt_length = len(prompt_tokenized[\"input_ids\"])\n",
    "\n",
    "    labels = tokenized[\"input_ids\"].copy()\n",
    "    labels[:prompt_length] = [-100] * prompt_length\n",
    "    tokenized[\"labels\"] = labels\n",
    "    return tokenized\n",
    "\n",
    "def train_preprocess_tokenclass(dataset_id: str, token_list: list[int], example: dict):\n",
    "    # Create prompt and target text\n",
    "    args = [example[key] for key in prompt_args[dataset_id]]\n",
    "    prompt = prompt_templates[dataset_id].format(*args)\n",
    "\n",
    "    # tokenize text\n",
    "    tokenized = tokenizer(prompt,\n",
    "                          truncation=True,\n",
    "                          padding=\"max_length\",\n",
    "                          max_length=MAX_LENGTH)\n",
    "\n",
    "    # tokenize and index label\n",
    "    target = id2labels[dataset_id][example[\"label\"]]\n",
    "    token_target = tokenizer.encode(target, add_special_tokens=False)[0]\n",
    "    label = token_list.index(token_target)\n",
    "    tokenized[\"labels\"] = label\n",
    "\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4db6a3b401624655a531b6a7886d0e36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3876 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9bc72de61bb49f5b9a54908a70cb9bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "415ed28c8d48407ca99b713ca7f6ef88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nrows_list = [3876, 5000, 5000]\n",
    "dataset_list = []\n",
    "for i, (dataset_id, dataset_path) in enumerate(paths.items()):\n",
    "    train_subset = pd.read_csv(dataset_path / \"train.csv\",\n",
    "                                delimiter=del_mapping[dataset_id],\n",
    "                                names=names_mapping[dataset_id],\n",
    "                                nrows=nrows_list[i])\n",
    "\n",
    "    preprocess_func = partial(train_preprocess_tokenclass, dataset_id, token_list)\n",
    "    dataset_list.append(Dataset\n",
    "                        .from_pandas(train_subset)\n",
    "                        .map(preprocess_func, batched=False)\n",
    "                        .remove_columns(columns[dataset_id]))\n",
    "\n",
    "n_datasets = len(dataset_list)\n",
    "train_dataset = interleave_datasets(dataset_list, \n",
    "                                    probabilities=[1/n_datasets]*n_datasets,\n",
    "                                    seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9a8589480404e2aa44b9a69343262eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/11489 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "save_path = dataset_cache_path.with_stem(\"finmoe-tokenclass_medium-len512\")\n",
    "train_dataset.save_to_disk(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_path = dataset_cache_path.with_stem(\"finmoe-tokenclass-len512\")\n",
    "train_dataset = Dataset.load_from_disk(load_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peft Model trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.01,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"]\n",
    ")\n",
    "\n",
    "model_id = \"meta-llama/Llama-3.2-1B\"\n",
    "base_model = LlamaForCausalLM.from_pretrained(model_id, torch_dtype=\"float16\")\n",
    "\n",
    "peft_model = get_peft_model(base_model, peft_config)\n",
    "peft_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, mlm=False\n",
    ")\n",
    "\n",
    "out_dir = Path(rf\"D:/models/general-Llama-3_2-3B\")\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=str(out_dir),\n",
    "    num_train_epochs=6,\n",
    "    per_device_train_batch_size=2,\n",
    "    learning_rate=1e-3,\n",
    "    weight_decay=0.01,\n",
    "    warmup_steps=1000,\n",
    "    save_strategy=\"epoch\",\n",
    "    do_train=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=peft_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FinMoE trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\samba\\OneDrive - Durham University\\L4\\Project\\code\\venv\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:774: UserWarning: `return_dict_in_generate` is NOT set to `True`, but `output_hidden_states` is. When `return_dict_in_generate` is not `True`, `output_hidden_states` is ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory allocated: 4953515008\n",
      "Trainable params:\n",
      "gate.w_gate.weight torch.Size([3, 2048])\n",
      "gate.w_gate.bias torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "from FinMoE import FinMoE, FinMoEConfig\n",
    "\n",
    "ckpt_base = Path(r\"D:\\models\")\n",
    "expert_ids = {\"FPB\": \"checkpoint-best\",\n",
    "              \"Headline\": \"checkpoint-best\",\n",
    "              \"Topics\": \"checkpoint-best\"}\n",
    "\n",
    "## note: str() wraps path as Path objects are not json serializable\n",
    "expert_ckpts = [str(ckpt_base / f\"expert-Llama-3_2-1B-{expert_name}\" / ckpt_name)\n",
    "                for expert_name, ckpt_name in expert_ids.items()]\n",
    "\n",
    "finMoE_config = FinMoEConfig(\n",
    "    # loss_type=\"ForCausalLM\",\n",
    "    loss_type=\"ForTokenClassification\",\n",
    "    num_labels=len(token_list),\n",
    "\n",
    "    expert_ckpts=expert_ckpts,\n",
    "    token_list=token_list,\n",
    ")\n",
    "\n",
    "finMoE_model = FinMoE(finMoE_config).to(device)\n",
    "print(\"Memory allocated:\", torch.cuda.memory_allocated())\n",
    "print(\"Trainable params:\")\n",
    "for name, params in finMoE_model.named_parameters():\n",
    "    if params.requires_grad:\n",
    "        print(name, params.shape)\n",
    "\n",
    "# data_collator = DataCollatorForLanguageModeling(\n",
    "#     tokenizer=tokenizer, mlm=False\n",
    "# )\n",
    "\n",
    "out_dir = Path(rf\"D:/models/FinMoE-v2\")\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=str(out_dir),\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=8,\n",
    "    learning_rate=1e-3,\n",
    "    weight_decay=0.01,\n",
    "    warmup_steps=256,\n",
    "    logging_steps=128,\n",
    "    save_strategy=\"epoch\",\n",
    "    do_train=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=finMoE_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    # data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0af96906aa304f029c4790d75a5dbcae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7180 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 20.8188, 'grad_norm': 211.09530639648438, 'learning_rate': 0.0005, 'epoch': 0.09}\n",
      "{'loss': 21.1283, 'grad_norm': 400.69146728515625, 'learning_rate': 0.001, 'epoch': 0.18}\n",
      "{'loss': 21.0356, 'grad_norm': 310.02655029296875, 'learning_rate': 0.0009815135759676488, 'epoch': 0.27}\n",
      "{'loss': 22.4787, 'grad_norm': 371.5384216308594, 'learning_rate': 0.0009630271519352975, 'epoch': 0.36}\n",
      "{'loss': 20.1923, 'grad_norm': 132.94309997558594, 'learning_rate': 0.0009445407279029464, 'epoch': 0.45}\n",
      "{'loss': 19.7472, 'grad_norm': 404.6505432128906, 'learning_rate': 0.0009260543038705951, 'epoch': 0.53}\n",
      "{'loss': 21.4861, 'grad_norm': 584.789794921875, 'learning_rate': 0.0009075678798382439, 'epoch': 0.62}\n",
      "{'loss': 20.2967, 'grad_norm': 271.59283447265625, 'learning_rate': 0.0008890814558058926, 'epoch': 0.71}\n",
      "{'loss': 20.8726, 'grad_norm': 264.4077453613281, 'learning_rate': 0.0008705950317735413, 'epoch': 0.8}\n",
      "{'loss': 20.376, 'grad_norm': 36.91596221923828, 'learning_rate': 0.00085210860774119, 'epoch': 0.89}\n",
      "{'loss': 21.7846, 'grad_norm': 156.38685607910156, 'learning_rate': 0.0008336221837088388, 'epoch': 0.98}\n",
      "{'loss': 20.2733, 'grad_norm': 280.1829528808594, 'learning_rate': 0.0008151357596764875, 'epoch': 1.07}\n",
      "{'loss': 19.6883, 'grad_norm': 387.39764404296875, 'learning_rate': 0.0007966493356441364, 'epoch': 1.16}\n",
      "{'loss': 22.0852, 'grad_norm': 353.250732421875, 'learning_rate': 0.0007781629116117851, 'epoch': 1.25}\n",
      "{'loss': 21.6209, 'grad_norm': 315.96728515625, 'learning_rate': 0.0007596764875794339, 'epoch': 1.34}\n",
      "{'loss': 22.1532, 'grad_norm': 393.33843994140625, 'learning_rate': 0.0007411900635470826, 'epoch': 1.43}\n",
      "{'loss': 19.4657, 'grad_norm': 306.5478515625, 'learning_rate': 0.0007227036395147314, 'epoch': 1.52}\n",
      "{'loss': 21.3986, 'grad_norm': 220.88037109375, 'learning_rate': 0.0007042172154823801, 'epoch': 1.6}\n",
      "{'loss': 21.0546, 'grad_norm': 363.509765625, 'learning_rate': 0.000685730791450029, 'epoch': 1.69}\n",
      "{'loss': 20.0014, 'grad_norm': 321.6959533691406, 'learning_rate': 0.0006672443674176777, 'epoch': 1.78}\n",
      "{'loss': 20.0043, 'grad_norm': 59.959388732910156, 'learning_rate': 0.0006487579433853265, 'epoch': 1.87}\n",
      "{'loss': 20.9914, 'grad_norm': 212.0589141845703, 'learning_rate': 0.0006302715193529752, 'epoch': 1.96}\n",
      "{'loss': 19.3534, 'grad_norm': 299.8324279785156, 'learning_rate': 0.0006117850953206239, 'epoch': 2.05}\n",
      "{'loss': 20.1839, 'grad_norm': 665.3788452148438, 'learning_rate': 0.0005932986712882726, 'epoch': 2.14}\n",
      "{'loss': 20.4187, 'grad_norm': 207.40647888183594, 'learning_rate': 0.0005748122472559214, 'epoch': 2.23}\n",
      "{'loss': 20.9813, 'grad_norm': 69.72766876220703, 'learning_rate': 0.0005563258232235701, 'epoch': 2.32}\n",
      "{'loss': 21.7843, 'grad_norm': 134.13121032714844, 'learning_rate': 0.000537839399191219, 'epoch': 2.41}\n",
      "{'loss': 20.9709, 'grad_norm': 209.80990600585938, 'learning_rate': 0.0005193529751588677, 'epoch': 2.5}\n",
      "{'loss': 20.7177, 'grad_norm': 307.2684631347656, 'learning_rate': 0.0005008665511265165, 'epoch': 2.58}\n",
      "{'loss': 20.4187, 'grad_norm': 225.6254119873047, 'learning_rate': 0.00048238012709416524, 'epoch': 2.67}\n",
      "{'loss': 19.8965, 'grad_norm': 442.98480224609375, 'learning_rate': 0.000463893703061814, 'epoch': 2.76}\n",
      "{'loss': 20.2234, 'grad_norm': 348.458740234375, 'learning_rate': 0.00044540727902946277, 'epoch': 2.85}\n",
      "{'loss': 19.1524, 'grad_norm': 230.32418823242188, 'learning_rate': 0.00042692085499711153, 'epoch': 2.94}\n",
      "{'loss': 18.3167, 'grad_norm': 349.6977233886719, 'learning_rate': 0.00040843443096476024, 'epoch': 3.03}\n",
      "{'loss': 18.1817, 'grad_norm': 271.4065856933594, 'learning_rate': 0.000389948006932409, 'epoch': 3.12}\n",
      "{'loss': 18.561, 'grad_norm': 145.72119140625, 'learning_rate': 0.00037146158290005777, 'epoch': 3.21}\n",
      "{'loss': 16.0621, 'grad_norm': 179.20213317871094, 'learning_rate': 0.00035297515886770653, 'epoch': 3.3}\n",
      "{'loss': 14.4335, 'grad_norm': 193.00897216796875, 'learning_rate': 0.0003344887348353553, 'epoch': 3.39}\n",
      "{'loss': 16.4248, 'grad_norm': 227.88063049316406, 'learning_rate': 0.00031600231080300406, 'epoch': 3.48}\n",
      "{'loss': 15.0709, 'grad_norm': 146.84671020507812, 'learning_rate': 0.0002975158867706528, 'epoch': 3.57}\n",
      "{'loss': 13.3772, 'grad_norm': 88.47737884521484, 'learning_rate': 0.00027902946273830154, 'epoch': 3.65}\n",
      "{'loss': 14.333, 'grad_norm': 300.3883972167969, 'learning_rate': 0.0002605430387059503, 'epoch': 3.74}\n",
      "{'loss': 15.4652, 'grad_norm': 238.46157836914062, 'learning_rate': 0.00024205661467359906, 'epoch': 3.83}\n",
      "{'loss': 14.6766, 'grad_norm': 251.5666046142578, 'learning_rate': 0.00022357019064124783, 'epoch': 3.92}\n",
      "{'loss': 14.8607, 'grad_norm': 228.09805297851562, 'learning_rate': 0.00020508376660889662, 'epoch': 4.01}\n",
      "{'loss': 14.038, 'grad_norm': 151.2871856689453, 'learning_rate': 0.00018659734257654535, 'epoch': 4.1}\n",
      "{'loss': 12.8236, 'grad_norm': 289.7481994628906, 'learning_rate': 0.00016811091854419412, 'epoch': 4.19}\n",
      "{'loss': 13.658, 'grad_norm': 138.9285888671875, 'learning_rate': 0.00014962449451184288, 'epoch': 4.28}\n",
      "{'loss': 14.3235, 'grad_norm': 294.7852783203125, 'learning_rate': 0.00013113807047949164, 'epoch': 4.37}\n",
      "{'loss': 13.1496, 'grad_norm': 252.96226501464844, 'learning_rate': 0.00011265164644714038, 'epoch': 4.46}\n",
      "{'loss': 14.381, 'grad_norm': 265.5154724121094, 'learning_rate': 9.416522241478915e-05, 'epoch': 4.55}\n",
      "{'loss': 14.3596, 'grad_norm': 264.4455261230469, 'learning_rate': 7.56787983824379e-05, 'epoch': 4.63}\n",
      "{'loss': 13.3421, 'grad_norm': 112.76914978027344, 'learning_rate': 5.719237435008666e-05, 'epoch': 4.72}\n",
      "{'loss': 14.0868, 'grad_norm': 309.7771301269531, 'learning_rate': 3.870595031773541e-05, 'epoch': 4.81}\n",
      "{'loss': 13.2382, 'grad_norm': 259.27703857421875, 'learning_rate': 2.0219526285384173e-05, 'epoch': 4.9}\n",
      "{'loss': 14.5399, 'grad_norm': 236.70176696777344, 'learning_rate': 1.7331022530329288e-06, 'epoch': 4.99}\n",
      "{'train_runtime': 30382.7221, 'train_samples_per_second': 1.891, 'train_steps_per_second': 0.236, 'train_loss': 18.29993851005533, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=7180, training_loss=18.29993851005533, metrics={'train_runtime': 30382.7221, 'train_samples_per_second': 1.891, 'train_steps_per_second': 0.236, 'total_flos': 1.7216924738371584e+17, 'train_loss': 18.29993851005533, 'epoch': 4.99956480111411})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36004e96ccd3479dbbf67bb138ee065c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ckpt_path = Path(r\"D:/models/general-Llama-3_2-3B\") / \"checkpoint-best\"\n",
    "\n",
    "model_id = \"meta-llama/Llama-3.2-3B\"\n",
    "base_model = LlamaForCausalLM.from_pretrained(model_id, torch_dtype=\"float16\") #.to(device)\n",
    "expert_model = PeftModel.from_pretrained(base_model, ckpt_path, torch_dtype=\"float16\").eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FinMoE import FinMoE\n",
    "\n",
    "ckpt_path = Path(rf\"D:/models/FinMoE-v1\") / \"checkpoint-34464\"\n",
    "finMoE_model = FinMoE.load_pretrained(ckpt_path).to(device).eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For FPB and Headline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_preprocess_a(example, max_length=512):\n",
    "    zeroshot = example['input'].rsplit(\"\\n\\n\", maxsplit=1)[-1]\n",
    "    return tokenizer(zeroshot,\n",
    "                     truncation=True,\n",
    "                     padding=\"max_length\",\n",
    "                     max_length=max_length,\n",
    "                     return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd53ed54bd454661835fa3703e76943b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/970 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_id = \"FPB\"\n",
    "testset_adaptllm = load_dataset(\"AdaptLLM/finance-tasks\", dataset_id, split=\"test\").map(eval_preprocess_a, batched=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28.03:  16%|█▌        | 157/970 [00:54<04:44,  2.86it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m tok_options \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFPB\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;241m59794\u001b[39m, \u001b[38;5;241m45003\u001b[39m, \u001b[38;5;241m51957\u001b[39m],    \u001b[38;5;66;03m# \" Neutral\", \" Positive\", \" Negative\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHeadline\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;241m7566\u001b[39m, \u001b[38;5;241m2360\u001b[39m],        \u001b[38;5;66;03m# \" Yes\", \" No\"\u001b[39;00m\n\u001b[0;32m      4\u001b[0m }\n\u001b[1;32m----> 6\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfinMoE_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mtestset_adaptllm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mguidance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mtok_opts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtok_options\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdataset_id\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(results)\n",
      "File \u001b[1;32mc:\\Users\\samba\\OneDrive - Durham University\\L4\\Project\\code\\evals.py:25\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(model, tokenizer, testset, guidance, tok_opts)\u001b[0m\n\u001b[0;32m     22\u001b[0m attn_mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(example[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     23\u001b[0m gen_idx \u001b[38;5;241m=\u001b[39m attn_mask\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mlong() \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 25\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m logits \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mlogits\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[0;32m     29\u001b[0m gen_logits \u001b[38;5;241m=\u001b[39m logits[torch\u001b[38;5;241m.\u001b[39marange(logits\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)), gen_idx, :] \u001b[38;5;66;03m# (B, C)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\samba\\OneDrive - Durham University\\L4\\Project\\code\\FinMoE.py:112\u001b[0m, in \u001b[0;36mFinMoE.forward\u001b[1;34m(self, input_ids, attention_mask, labels, **loss_kwargs)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    106\u001b[0m     input_ids: Optional[torch\u001b[38;5;241m.\u001b[39mLongTensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    110\u001b[0m ):\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;66;03m## expert routing probs\u001b[39;00m\n\u001b[1;32m--> 112\u001b[0m     expert_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (B, E)\u001b[39;00m\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;66;03m## select top-1 expert index for each sample\u001b[39;00m\n\u001b[0;32m    115\u001b[0m     top1_indices \u001b[38;5;241m=\u001b[39m expert_probs\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# (B,)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\samba\\OneDrive - Durham University\\L4\\Project\\code\\FinMoE.py:49\u001b[0m, in \u001b[0;36mTop1Gating.forward\u001b[1;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_ids, attention_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m---> 49\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllama\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state  \u001b[38;5;66;03m# (B, T, C)\u001b[39;00m\n\u001b[0;32m     52\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(hidden_states) \u001b[38;5;66;03m## TODO: is this norm layer necessary?\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\samba\\OneDrive - Durham University\\L4\\Project\\code\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\samba\\OneDrive - Durham University\\L4\\Project\\code\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\samba\\OneDrive - Durham University\\L4\\Project\\code\\venv\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:945\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[1;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[0;32m    933\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    934\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m    935\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    942\u001b[0m         position_embeddings,\n\u001b[0;32m    943\u001b[0m     )\n\u001b[0;32m    944\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 945\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    946\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    947\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    948\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    949\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    950\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    951\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    952\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    953\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    954\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    956\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    958\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32mc:\\Users\\samba\\OneDrive - Durham University\\L4\\Project\\code\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\samba\\OneDrive - Durham University\\L4\\Project\\code\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\samba\\OneDrive - Durham University\\L4\\Project\\code\\venv\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:676\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[0;32m    673\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm(hidden_states)\n\u001b[0;32m    675\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[1;32m--> 676\u001b[0m hidden_states, self_attn_weights, present_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    680\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    681\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    682\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    683\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    684\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    686\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    687\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[0;32m    689\u001b[0m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\samba\\OneDrive - Durham University\\L4\\Project\\code\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\samba\\OneDrive - Durham University\\L4\\Project\\code\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\samba\\OneDrive - Durham University\\L4\\Project\\code\\venv\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:614\u001b[0m, in \u001b[0;36mLlamaSdpaAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[0;32m    611\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[0;32m    612\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mview(bsz, q_len, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 614\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mo_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    616\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m attn_output, \u001b[38;5;28;01mNone\u001b[39;00m, past_key_value\n",
      "File \u001b[1;32mc:\\Users\\samba\\OneDrive - Durham University\\L4\\Project\\code\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\samba\\OneDrive - Durham University\\L4\\Project\\code\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\samba\\OneDrive - Durham University\\L4\\Project\\code\\venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tok_options = {\n",
    "    \"FPB\": [59794, 45003, 51957],    # \" Neutral\", \" Positive\", \" Negative\"\n",
    "    \"Headline\": [7566, 2360],        # \" Yes\", \" No\"\n",
    "}\n",
    "\n",
    "results = evaluate(finMoE_model, tokenizer,\n",
    "                   testset_adaptllm,\n",
    "                   guidance=True,\n",
    "                   tok_opts=tok_options[dataset_id])\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_preprocess_b(example, max_length=512):\n",
    "    zeroshot = prompt_templates[\"Topics\"].format(example[\"text\"])\n",
    "    return tokenizer(zeroshot,\n",
    "                     truncation=True,\n",
    "                     padding=\"max_length\",\n",
    "                     max_length=max_length,\n",
    "                     return_tensors=\"pt\")\n",
    "\n",
    "topic_options = [str(i) for i in range(len(topics))]\n",
    "def add_options(example):\n",
    "    example[\"options\"] = topic_options\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4d16df105bd4ecfa20901bdd9e5e9e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/850 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b71203348f1473081f3e6a1d275fbf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/850 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_id = \"Topics\"\n",
    "\n",
    "dataset_path = paths[dataset_id]\n",
    "testset_df = pd.read_csv(dataset_path / \"test.csv\",\n",
    "                            delimiter=del_mapping[dataset_id],\n",
    "                            names=names_mapping[dataset_id])\n",
    "testset_topics = (Dataset\n",
    "           .from_pandas(testset_df)\n",
    "           .map(eval_preprocess_b, batched=False)\n",
    "           .map(add_options, batched=False)\n",
    "           .rename_column(\"label\", \"gold_index\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_opts_ids = tokenizer(topic_options)[\"input_ids\"]\n",
    "tok_opts = [arr[1] for arr in tok_opts_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "82.59: 100%|██████████| 850/850 [02:47<00:00,  5.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.8258823529411765}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = evaluate(expert_model, tokenizer,\n",
    "                   testset_topics,\n",
    "                   guidance=True,\n",
    "                   tok_opts=tok_opts)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
