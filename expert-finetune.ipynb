{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import evaluate\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from peft import get_peft_model, LoraConfig, TaskType, PeftModel\n",
    "from datasets import Dataset, load_dataset\n",
    "from transformers import Trainer, TrainingArguments, AutoTokenizer, DataCollatorForLanguageModeling\n",
    "from transformers.models.llama.modeling_llama import LlamaForCausalLM\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "assert torch.cuda.is_available(), \"CUDA not available\"\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "model_id = \"meta-llama/Llama-3.2-1B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "base_model = LlamaForCausalLM.from_pretrained(model_id, torch_dtype=\"float16\")\n",
    "\n",
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "f1_metric = evaluate.load(\"f1\")\n",
    "\n",
    "dataset_id = \"Headline\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load_dataset causes an error, load directly from cached snapshot files\n",
    "hub_basepath = Path(r\"C:\\Users\\samba\\.cache\\huggingface\\hub\")\n",
    "\n",
    "paths = {\n",
    "    \"FPB\": hub_basepath / r\"datasets--AdaptLLM--FPB\\snapshots\\7f203bd82f0b2b01ce391b9451c642dd732cf381\",\n",
    "    \"Headline\": hub_basepath / r\"datasets--AdaptLLM--Headline\\snapshots\\68cf1056f3ed51d39b945d004259473759555559\",\n",
    "    \"FiQA_SA\": hub_basepath / r\"datasets--AdaptLLM--FiQA_SA\\snapshots\\302a1fafc3ce5fdaec33548db39e5a80b0d51038\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_mapping = {\n",
    "    \"FPB\": [\"text\", \"label\"],\n",
    "    \"Headline\": [\"idx\", \"text\", \"question\", \"label\", \"subidx\"],\n",
    "    \"FiQA_SA\": [\"Body ID\", \"text\", \"ticker\", \"label\"]\n",
    "}\n",
    "\n",
    "dataset_path = paths[dataset_id]\n",
    "train_dataset = pd.read_csv(dataset_path / \"train.csv\", delimiter=\"\\t\", names=names_mapping[dataset_id])\n",
    "test_dataset  = pd.read_csv(dataset_path / \"test.csv\",  delimiter=\"\\t\", names=names_mapping[dataset_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_cols = {\n",
    "    \"FPB\": [\"text\"],\n",
    "    \"Headline\": [\"text\", \"question\"],\n",
    "    \"FiQA_SA\": [\"text\", \"ticker\"],\n",
    "}\n",
    "\n",
    "prompt_templates = {\n",
    "    \"FPB\": \"{0}\\nQuestion: what is the sentiment?\\nOptions:\\n- Positive\\n- Negative\\n- Neutral\",\n",
    "    \"Headline\": \"Headline: \\\"{0}\\\" Now answer this question: {1}\",\n",
    "    \"FiQA_SA\": \"{0}\\nWhat is the sentiment on \\\"{1}\\\" in this sentence?\\nOptions:\\n- Positive\\n- Negative\\n- Neutral\",\n",
    "}\n",
    "\n",
    "id2labels = {\n",
    "    \"FPB\": {\"neutral\": \" Neutral\", \"positive\": \" Positive\", \"negative\": \" Negative\"},\n",
    "    \"Headline\": {0: \" No\", 1: \" Yes\"},\n",
    "    \"FiQA_SA\": {0: \" Neutral\", 2: \" Positive\", 1: \" Negative\"},\n",
    "}\n",
    "\n",
    "def train_preprocess(example: dict, max_length=512):\n",
    "    # Create prompt and target text\n",
    "    args = [example[key] for key in dataset_cols[dataset_id]]\n",
    "    prompt = prompt_templates[dataset_id].format(*args)\n",
    "\n",
    "    target = id2labels[dataset_id][example[\"label\"]]\n",
    "    full_text = prompt + target\n",
    "\n",
    "    # tokenize text\n",
    "    tokenized = tokenizer(full_text,\n",
    "                          truncation=True,\n",
    "                          padding=\"max_length\",\n",
    "                          max_length=max_length)\n",
    "    \n",
    "    # add padding tokens\n",
    "    prompt_tokenized = tokenizer(prompt,\n",
    "                              truncation=True,\n",
    "                              max_length=max_length)\n",
    "    prompt_length = len(prompt_tokenized[\"input_ids\"])\n",
    "\n",
    "    labels = tokenized[\"input_ids\"].copy()\n",
    "    labels[:prompt_length] = [-100] * prompt_length\n",
    "    tokenized[\"labels\"] = labels\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06b4e50ecf994d9f99922cf93dbcc0ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/82161 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab0f4de9831e46688e971dc62a1e0cad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20547 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = Dataset.from_pandas(train_dataset).map(train_preprocess, batched=False).remove_columns(names_mapping[dataset_id])\n",
    "val_dataset   = Dataset.from_pandas(test_dataset).map(train_preprocess, batched=False).remove_columns(names_mapping[dataset_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LoRA Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 851,968 || all params: 1,236,666,368 || trainable%: 0.0689\n"
     ]
    }
   ],
   "source": [
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.01,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"]\n",
    ")\n",
    "\n",
    "peft_model = get_peft_model(base_model, peft_config)\n",
    "peft_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, mlm=False\n",
    ")\n",
    "\n",
    "lr = 1e-3\n",
    "num_epochs = 2\n",
    "batch_size = 2\n",
    "\n",
    "out_dir = Path(rf\"D:/models/basic-Llama-3_2-LoRA-{dataset_id}\")\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=str(out_dir),\n",
    "    num_train_epochs=num_epochs,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    learning_rate=lr,\n",
    "    weight_decay=0.01,\n",
    "    warmup_steps=1000,\n",
    "    save_strategy=\"epoch\",\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=peft_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22b0f89eef844777a32724a466beb3c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/82162 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.793, 'grad_norm': 3.2848801612854004, 'learning_rate': 0.0005, 'epoch': 0.01}\n",
      "{'loss': 1.3802, 'grad_norm': 2.7161777019500732, 'learning_rate': 0.001, 'epoch': 0.02}\n",
      "{'loss': 1.4455, 'grad_norm': 2.013709545135498, 'learning_rate': 0.0009938394815307656, 'epoch': 0.04}\n",
      "{'loss': 1.2632, 'grad_norm': 5.033692836761475, 'learning_rate': 0.0009876789630615312, 'epoch': 0.05}\n",
      "{'loss': 1.1933, 'grad_norm': 2.3909170627593994, 'learning_rate': 0.0009815184445922968, 'epoch': 0.06}\n",
      "{'loss': 1.1689, 'grad_norm': 2.631848096847534, 'learning_rate': 0.0009753579261230625, 'epoch': 0.07}\n",
      "{'loss': 1.1381, 'grad_norm': 3.224199056625366, 'learning_rate': 0.0009691974076538281, 'epoch': 0.09}\n",
      "{'loss': 1.1141, 'grad_norm': 3.8480710983276367, 'learning_rate': 0.0009630368891845938, 'epoch': 0.1}\n",
      "{'loss': 1.1315, 'grad_norm': 2.9922499656677246, 'learning_rate': 0.0009568763707153594, 'epoch': 0.11}\n",
      "{'loss': 1.1289, 'grad_norm': 4.0397443771362305, 'learning_rate': 0.000950715852246125, 'epoch': 0.12}\n",
      "{'loss': 1.1151, 'grad_norm': 2.841416597366333, 'learning_rate': 0.0009445553337768907, 'epoch': 0.13}\n",
      "{'loss': 1.1018, 'grad_norm': 4.198047161102295, 'learning_rate': 0.0009383948153076564, 'epoch': 0.15}\n",
      "{'loss': 1.0989, 'grad_norm': 1.4967855215072632, 'learning_rate': 0.000932234296838422, 'epoch': 0.16}\n",
      "{'loss': 1.1184, 'grad_norm': 4.223813533782959, 'learning_rate': 0.0009260737783691876, 'epoch': 0.17}\n",
      "{'loss': 1.0979, 'grad_norm': 2.002041816711426, 'learning_rate': 0.0009199132598999532, 'epoch': 0.18}\n",
      "{'loss': 1.0976, 'grad_norm': 2.5118043422698975, 'learning_rate': 0.0009137527414307189, 'epoch': 0.19}\n",
      "{'loss': 1.0782, 'grad_norm': 5.52925968170166, 'learning_rate': 0.0009075922229614845, 'epoch': 0.21}\n",
      "{'loss': 1.0685, 'grad_norm': 1.9082294702529907, 'learning_rate': 0.0009014317044922501, 'epoch': 0.22}\n",
      "{'loss': 1.0834, 'grad_norm': 3.525333881378174, 'learning_rate': 0.0008952711860230157, 'epoch': 0.23}\n",
      "{'loss': 1.0875, 'grad_norm': 1.4605785608291626, 'learning_rate': 0.0008891106675537814, 'epoch': 0.24}\n",
      "{'loss': 1.0786, 'grad_norm': 3.084174156188965, 'learning_rate': 0.000882950149084547, 'epoch': 0.26}\n",
      "{'loss': 1.0724, 'grad_norm': 2.6153564453125, 'learning_rate': 0.0008767896306153126, 'epoch': 0.27}\n",
      "{'loss': 1.0875, 'grad_norm': 3.66605544090271, 'learning_rate': 0.0008706291121460782, 'epoch': 0.28}\n",
      "{'loss': 1.0618, 'grad_norm': 2.682685375213623, 'learning_rate': 0.0008644685936768439, 'epoch': 0.29}\n",
      "{'loss': 1.0653, 'grad_norm': 1.4225847721099854, 'learning_rate': 0.0008583080752076095, 'epoch': 0.3}\n",
      "{'loss': 1.0659, 'grad_norm': 4.8124799728393555, 'learning_rate': 0.0008521475567383751, 'epoch': 0.32}\n",
      "{'loss': 1.0111, 'grad_norm': 1.6662709712982178, 'learning_rate': 0.0008459870382691407, 'epoch': 0.33}\n",
      "{'loss': 1.0418, 'grad_norm': 4.0334153175354, 'learning_rate': 0.0008398265197999065, 'epoch': 0.34}\n",
      "{'loss': 1.0642, 'grad_norm': 2.0462114810943604, 'learning_rate': 0.0008336660013306721, 'epoch': 0.35}\n",
      "{'loss': 1.0565, 'grad_norm': 3.0786473751068115, 'learning_rate': 0.0008275054828614377, 'epoch': 0.37}\n",
      "{'loss': 1.047, 'grad_norm': 1.9421008825302124, 'learning_rate': 0.0008213449643922033, 'epoch': 0.38}\n",
      "{'loss': 1.0568, 'grad_norm': 3.87776517868042, 'learning_rate': 0.000815184445922969, 'epoch': 0.39}\n",
      "{'loss': 1.0362, 'grad_norm': 1.3451032638549805, 'learning_rate': 0.0008090239274537345, 'epoch': 0.4}\n",
      "{'loss': 1.0602, 'grad_norm': 2.6784379482269287, 'learning_rate': 0.0008028634089845001, 'epoch': 0.41}\n",
      "{'loss': 1.0266, 'grad_norm': 2.821981191635132, 'learning_rate': 0.0007967028905152657, 'epoch': 0.43}\n",
      "{'loss': 1.0349, 'grad_norm': 1.7129645347595215, 'learning_rate': 0.0007905423720460314, 'epoch': 0.44}\n",
      "{'loss': 1.0433, 'grad_norm': 2.5444185733795166, 'learning_rate': 0.000784381853576797, 'epoch': 0.45}\n",
      "{'loss': 1.0462, 'grad_norm': 3.348870277404785, 'learning_rate': 0.0007782213351075626, 'epoch': 0.46}\n",
      "{'loss': 1.0152, 'grad_norm': 2.6539926528930664, 'learning_rate': 0.0007720608166383282, 'epoch': 0.47}\n",
      "{'loss': 1.0219, 'grad_norm': 1.7166671752929688, 'learning_rate': 0.0007659002981690939, 'epoch': 0.49}\n",
      "{'loss': 1.0253, 'grad_norm': 3.1796302795410156, 'learning_rate': 0.0007597397796998595, 'epoch': 0.5}\n",
      "{'loss': 1.0285, 'grad_norm': 4.5341997146606445, 'learning_rate': 0.0007535792612306251, 'epoch': 0.51}\n",
      "{'loss': 0.9997, 'grad_norm': 4.911712646484375, 'learning_rate': 0.0007474187427613907, 'epoch': 0.52}\n",
      "{'loss': 1.0022, 'grad_norm': 2.5003628730773926, 'learning_rate': 0.0007412582242921564, 'epoch': 0.54}\n",
      "{'loss': 1.0028, 'grad_norm': 2.367934465408325, 'learning_rate': 0.0007350977058229221, 'epoch': 0.55}\n",
      "{'loss': 0.994, 'grad_norm': 3.183753490447998, 'learning_rate': 0.0007289371873536877, 'epoch': 0.56}\n",
      "{'loss': 1.017, 'grad_norm': 1.7058038711547852, 'learning_rate': 0.0007227766688844534, 'epoch': 0.57}\n",
      "{'loss': 0.9999, 'grad_norm': 2.687526226043701, 'learning_rate': 0.000716616150415219, 'epoch': 0.58}\n",
      "{'loss': 0.9982, 'grad_norm': 2.440955877304077, 'learning_rate': 0.0007104556319459846, 'epoch': 0.6}\n",
      "{'loss': 1.0036, 'grad_norm': 2.1359269618988037, 'learning_rate': 0.0007042951134767502, 'epoch': 0.61}\n",
      "{'loss': 0.9758, 'grad_norm': 3.0041980743408203, 'learning_rate': 0.0006981345950075159, 'epoch': 0.62}\n",
      "{'loss': 1.0081, 'grad_norm': 1.8932541608810425, 'learning_rate': 0.0006919740765382815, 'epoch': 0.63}\n",
      "{'loss': 0.9861, 'grad_norm': 3.4335203170776367, 'learning_rate': 0.0006858135580690471, 'epoch': 0.65}\n",
      "{'loss': 0.9909, 'grad_norm': 1.651139497756958, 'learning_rate': 0.0006796530395998127, 'epoch': 0.66}\n",
      "{'loss': 0.9973, 'grad_norm': 3.7931506633758545, 'learning_rate': 0.0006734925211305784, 'epoch': 0.67}\n",
      "{'loss': 0.9803, 'grad_norm': 2.0961318016052246, 'learning_rate': 0.000667332002661344, 'epoch': 0.68}\n",
      "{'loss': 0.9772, 'grad_norm': 1.8155043125152588, 'learning_rate': 0.0006611714841921096, 'epoch': 0.69}\n",
      "{'loss': 0.9954, 'grad_norm': 2.9052019119262695, 'learning_rate': 0.0006550109657228752, 'epoch': 0.71}\n",
      "{'loss': 0.9575, 'grad_norm': 6.134950160980225, 'learning_rate': 0.0006488504472536409, 'epoch': 0.72}\n",
      "{'loss': 0.9663, 'grad_norm': 6.389942646026611, 'learning_rate': 0.0006426899287844065, 'epoch': 0.73}\n",
      "{'loss': 0.976, 'grad_norm': 3.276928424835205, 'learning_rate': 0.0006365294103151721, 'epoch': 0.74}\n",
      "{'loss': 0.9871, 'grad_norm': 3.879953622817993, 'learning_rate': 0.0006303688918459378, 'epoch': 0.75}\n",
      "{'loss': 0.9595, 'grad_norm': 3.0640170574188232, 'learning_rate': 0.0006242083733767035, 'epoch': 0.77}\n",
      "{'loss': 0.9703, 'grad_norm': 3.4444515705108643, 'learning_rate': 0.0006180478549074691, 'epoch': 0.78}\n",
      "{'loss': 0.9384, 'grad_norm': 4.234454154968262, 'learning_rate': 0.0006118873364382347, 'epoch': 0.79}\n",
      "{'loss': 0.9486, 'grad_norm': 1.737061858177185, 'learning_rate': 0.0006057268179690003, 'epoch': 0.8}\n",
      "{'loss': 0.944, 'grad_norm': 2.81840443611145, 'learning_rate': 0.000599566299499766, 'epoch': 0.82}\n",
      "{'loss': 0.9763, 'grad_norm': 2.775031805038452, 'learning_rate': 0.0005934057810305316, 'epoch': 0.83}\n",
      "{'loss': 0.9348, 'grad_norm': 2.015183210372925, 'learning_rate': 0.0005872452625612972, 'epoch': 0.84}\n",
      "{'loss': 0.9542, 'grad_norm': 2.280177593231201, 'learning_rate': 0.0005810847440920628, 'epoch': 0.85}\n",
      "{'loss': 0.9461, 'grad_norm': 2.7995669841766357, 'learning_rate': 0.0005749242256228285, 'epoch': 0.86}\n",
      "{'loss': 0.9408, 'grad_norm': 1.0340747833251953, 'learning_rate': 0.000568763707153594, 'epoch': 0.88}\n",
      "{'loss': 0.9382, 'grad_norm': 2.346177101135254, 'learning_rate': 0.0005626031886843596, 'epoch': 0.89}\n",
      "{'loss': 0.9512, 'grad_norm': 2.564218282699585, 'learning_rate': 0.0005564426702151252, 'epoch': 0.9}\n",
      "{'loss': 0.9447, 'grad_norm': 2.84586763381958, 'learning_rate': 0.000550282151745891, 'epoch': 0.91}\n",
      "{'loss': 0.917, 'grad_norm': 1.6077574491500854, 'learning_rate': 0.0005441216332766565, 'epoch': 0.93}\n",
      "{'loss': 0.9318, 'grad_norm': 2.648066520690918, 'learning_rate': 0.0005379611148074221, 'epoch': 0.94}\n",
      "{'loss': 0.9017, 'grad_norm': 3.637375831604004, 'learning_rate': 0.0005318005963381877, 'epoch': 0.95}\n",
      "{'loss': 0.9262, 'grad_norm': 2.219130277633667, 'learning_rate': 0.0005256400778689535, 'epoch': 0.96}\n",
      "{'loss': 0.8966, 'grad_norm': 2.9512791633605957, 'learning_rate': 0.0005194795593997191, 'epoch': 0.97}\n",
      "{'loss': 0.9066, 'grad_norm': 1.460723876953125, 'learning_rate': 0.0005133190409304847, 'epoch': 0.99}\n",
      "{'loss': 0.9169, 'grad_norm': 5.244762420654297, 'learning_rate': 0.0005071585224612504, 'epoch': 1.0}\n",
      "{'loss': 0.8938, 'grad_norm': 1.7352690696716309, 'learning_rate': 0.000500998003992016, 'epoch': 1.01}\n",
      "{'loss': 0.8821, 'grad_norm': 1.8613039255142212, 'learning_rate': 0.0004948374855227816, 'epoch': 1.02}\n",
      "{'loss': 0.8951, 'grad_norm': 1.8313645124435425, 'learning_rate': 0.0004886769670535472, 'epoch': 1.03}\n",
      "{'loss': 0.8642, 'grad_norm': 3.138923168182373, 'learning_rate': 0.00048251644858431287, 'epoch': 1.05}\n",
      "{'loss': 0.89, 'grad_norm': 1.310124158859253, 'learning_rate': 0.0004763559301150785, 'epoch': 1.06}\n",
      "{'loss': 0.8775, 'grad_norm': 2.6837053298950195, 'learning_rate': 0.0004701954116458441, 'epoch': 1.07}\n",
      "{'loss': 0.8745, 'grad_norm': 3.5740246772766113, 'learning_rate': 0.00046403489317660976, 'epoch': 1.08}\n",
      "{'loss': 0.8551, 'grad_norm': 5.522663593292236, 'learning_rate': 0.00045787437470737536, 'epoch': 1.1}\n",
      "{'loss': 0.8787, 'grad_norm': 3.054090738296509, 'learning_rate': 0.000451713856238141, 'epoch': 1.11}\n",
      "{'loss': 0.8917, 'grad_norm': 2.697368860244751, 'learning_rate': 0.00044555333776890666, 'epoch': 1.12}\n",
      "{'loss': 0.8761, 'grad_norm': 2.1805968284606934, 'learning_rate': 0.0004393928192996723, 'epoch': 1.13}\n",
      "{'loss': 0.8706, 'grad_norm': 2.7776501178741455, 'learning_rate': 0.0004332323008304379, 'epoch': 1.14}\n",
      "{'loss': 0.8678, 'grad_norm': 1.7079390287399292, 'learning_rate': 0.00042707178236120355, 'epoch': 1.16}\n",
      "{'loss': 0.8675, 'grad_norm': 2.258854627609253, 'learning_rate': 0.00042091126389196914, 'epoch': 1.17}\n",
      "{'loss': 0.8508, 'grad_norm': 3.2776732444763184, 'learning_rate': 0.0004147507454227348, 'epoch': 1.18}\n",
      "{'loss': 0.8364, 'grad_norm': 3.0489413738250732, 'learning_rate': 0.0004085902269535004, 'epoch': 1.19}\n",
      "{'loss': 0.8573, 'grad_norm': 2.2345292568206787, 'learning_rate': 0.00040242970848426604, 'epoch': 1.2}\n",
      "{'loss': 0.8509, 'grad_norm': 4.619603633880615, 'learning_rate': 0.0003962691900150317, 'epoch': 1.22}\n",
      "{'loss': 0.8549, 'grad_norm': 1.893778681755066, 'learning_rate': 0.00039010867154579734, 'epoch': 1.23}\n",
      "{'loss': 0.8226, 'grad_norm': 1.644268274307251, 'learning_rate': 0.00038394815307656293, 'epoch': 1.24}\n",
      "{'loss': 0.8336, 'grad_norm': 0.9824791550636292, 'learning_rate': 0.0003777876346073286, 'epoch': 1.25}\n",
      "{'loss': 0.8218, 'grad_norm': 1.305670142173767, 'learning_rate': 0.0003716271161380942, 'epoch': 1.27}\n",
      "{'loss': 0.8312, 'grad_norm': 2.9889657497406006, 'learning_rate': 0.0003654665976688598, 'epoch': 1.28}\n",
      "{'loss': 0.8233, 'grad_norm': 1.1564027070999146, 'learning_rate': 0.0003593060791996254, 'epoch': 1.29}\n",
      "{'loss': 0.8257, 'grad_norm': 1.8945226669311523, 'learning_rate': 0.00035314556073039107, 'epoch': 1.3}\n",
      "{'loss': 0.8036, 'grad_norm': 1.901513934135437, 'learning_rate': 0.00034698504226115666, 'epoch': 1.31}\n",
      "{'loss': 0.813, 'grad_norm': 1.7955231666564941, 'learning_rate': 0.00034082452379192237, 'epoch': 1.33}\n",
      "{'loss': 0.8066, 'grad_norm': 2.0921988487243652, 'learning_rate': 0.00033466400532268796, 'epoch': 1.34}\n",
      "{'loss': 0.8211, 'grad_norm': 2.132828950881958, 'learning_rate': 0.0003285034868534536, 'epoch': 1.35}\n",
      "{'loss': 0.8069, 'grad_norm': 3.499246120452881, 'learning_rate': 0.0003223429683842192, 'epoch': 1.36}\n",
      "{'loss': 0.8219, 'grad_norm': 2.210395336151123, 'learning_rate': 0.00031618244991498486, 'epoch': 1.38}\n",
      "{'loss': 0.8102, 'grad_norm': 4.926162242889404, 'learning_rate': 0.00031002193144575045, 'epoch': 1.39}\n",
      "{'loss': 0.7888, 'grad_norm': 2.6115617752075195, 'learning_rate': 0.0003038614129765161, 'epoch': 1.4}\n",
      "{'loss': 0.8015, 'grad_norm': 1.3395781517028809, 'learning_rate': 0.0002977008945072817, 'epoch': 1.41}\n",
      "{'loss': 0.7916, 'grad_norm': 2.882995367050171, 'learning_rate': 0.0002915403760380474, 'epoch': 1.42}\n",
      "{'loss': 0.7662, 'grad_norm': 2.155041456222534, 'learning_rate': 0.000285379857568813, 'epoch': 1.44}\n",
      "{'loss': 0.7761, 'grad_norm': 4.100715160369873, 'learning_rate': 0.00027921933909957864, 'epoch': 1.45}\n",
      "{'loss': 0.7875, 'grad_norm': 2.0620861053466797, 'learning_rate': 0.00027305882063034424, 'epoch': 1.46}\n",
      "{'loss': 0.7741, 'grad_norm': 2.809757947921753, 'learning_rate': 0.0002668983021611099, 'epoch': 1.47}\n",
      "{'loss': 0.7759, 'grad_norm': 3.9997496604919434, 'learning_rate': 0.0002607377836918755, 'epoch': 1.48}\n",
      "{'loss': 0.754, 'grad_norm': 2.075636863708496, 'learning_rate': 0.00025457726522264113, 'epoch': 1.5}\n",
      "{'loss': 0.7702, 'grad_norm': 2.0567617416381836, 'learning_rate': 0.0002484167467534068, 'epoch': 1.51}\n",
      "{'loss': 0.7618, 'grad_norm': 2.521127223968506, 'learning_rate': 0.0002422562282841724, 'epoch': 1.52}\n",
      "{'loss': 0.7524, 'grad_norm': 3.0379841327667236, 'learning_rate': 0.00023609570981493802, 'epoch': 1.53}\n",
      "{'loss': 0.7632, 'grad_norm': 3.409444808959961, 'learning_rate': 0.00022993519134570365, 'epoch': 1.55}\n",
      "{'loss': 0.7452, 'grad_norm': 2.1698052883148193, 'learning_rate': 0.0002237746728764693, 'epoch': 1.56}\n",
      "{'loss': 0.7496, 'grad_norm': 3.913172483444214, 'learning_rate': 0.00021761415440723492, 'epoch': 1.57}\n",
      "{'loss': 0.7308, 'grad_norm': 3.2905733585357666, 'learning_rate': 0.00021145363593800054, 'epoch': 1.58}\n",
      "{'loss': 0.7418, 'grad_norm': 5.134576797485352, 'learning_rate': 0.00020529311746876616, 'epoch': 1.59}\n",
      "{'loss': 0.7361, 'grad_norm': 3.4804139137268066, 'learning_rate': 0.0001991325989995318, 'epoch': 1.61}\n",
      "{'loss': 0.7104, 'grad_norm': 2.375870704650879, 'learning_rate': 0.00019297208053029743, 'epoch': 1.62}\n",
      "{'loss': 0.7187, 'grad_norm': 3.7261149883270264, 'learning_rate': 0.00018681156206106305, 'epoch': 1.63}\n",
      "{'loss': 0.7062, 'grad_norm': 3.3204257488250732, 'learning_rate': 0.00018065104359182868, 'epoch': 1.64}\n",
      "{'loss': 0.7308, 'grad_norm': 2.074317216873169, 'learning_rate': 0.00017449052512259433, 'epoch': 1.66}\n",
      "{'loss': 0.7154, 'grad_norm': 4.734033107757568, 'learning_rate': 0.00016833000665335995, 'epoch': 1.67}\n",
      "{'loss': 0.701, 'grad_norm': 2.721229314804077, 'learning_rate': 0.00016216948818412557, 'epoch': 1.68}\n",
      "{'loss': 0.6929, 'grad_norm': 3.03621244430542, 'learning_rate': 0.0001560089697148912, 'epoch': 1.69}\n",
      "{'loss': 0.7049, 'grad_norm': 2.3002965450286865, 'learning_rate': 0.0001498484512456568, 'epoch': 1.7}\n",
      "{'loss': 0.6854, 'grad_norm': 2.3980538845062256, 'learning_rate': 0.00014368793277642246, 'epoch': 1.72}\n",
      "{'loss': 0.7031, 'grad_norm': 2.5722708702087402, 'learning_rate': 0.00013752741430718808, 'epoch': 1.73}\n",
      "{'loss': 0.6893, 'grad_norm': 1.2579865455627441, 'learning_rate': 0.00013136689583795373, 'epoch': 1.74}\n",
      "{'loss': 0.6927, 'grad_norm': 6.071534156799316, 'learning_rate': 0.00012520637736871936, 'epoch': 1.75}\n",
      "{'loss': 0.673, 'grad_norm': 1.415431261062622, 'learning_rate': 0.00011904585889948498, 'epoch': 1.76}\n",
      "{'loss': 0.6638, 'grad_norm': 2.9609076976776123, 'learning_rate': 0.00011288534043025061, 'epoch': 1.78}\n",
      "{'loss': 0.6612, 'grad_norm': 1.6651883125305176, 'learning_rate': 0.00010672482196101624, 'epoch': 1.79}\n",
      "{'loss': 0.6722, 'grad_norm': 5.005460262298584, 'learning_rate': 0.00010056430349178187, 'epoch': 1.8}\n",
      "{'loss': 0.6564, 'grad_norm': 1.961449146270752, 'learning_rate': 9.440378502254749e-05, 'epoch': 1.81}\n",
      "{'loss': 0.6505, 'grad_norm': 3.447890281677246, 'learning_rate': 8.824326655331313e-05, 'epoch': 1.83}\n",
      "{'loss': 0.6354, 'grad_norm': 3.091606855392456, 'learning_rate': 8.208274808407875e-05, 'epoch': 1.84}\n",
      "{'loss': 0.6567, 'grad_norm': 4.189265727996826, 'learning_rate': 7.592222961484439e-05, 'epoch': 1.85}\n",
      "{'loss': 0.6513, 'grad_norm': 2.700045108795166, 'learning_rate': 6.976171114561002e-05, 'epoch': 1.86}\n",
      "{'loss': 0.6312, 'grad_norm': 2.90263032913208, 'learning_rate': 6.360119267637564e-05, 'epoch': 1.87}\n",
      "{'loss': 0.6357, 'grad_norm': 1.7959767580032349, 'learning_rate': 5.744067420714127e-05, 'epoch': 1.89}\n",
      "{'loss': 0.6231, 'grad_norm': 2.781923770904541, 'learning_rate': 5.12801557379069e-05, 'epoch': 1.9}\n",
      "{'loss': 0.6408, 'grad_norm': 2.697537660598755, 'learning_rate': 4.511963726867253e-05, 'epoch': 1.91}\n",
      "{'loss': 0.6298, 'grad_norm': 2.3487727642059326, 'learning_rate': 3.8959118799438166e-05, 'epoch': 1.92}\n",
      "{'loss': 0.6161, 'grad_norm': 2.389143228530884, 'learning_rate': 3.2798600330203795e-05, 'epoch': 1.94}\n",
      "{'loss': 0.6065, 'grad_norm': 2.8493430614471436, 'learning_rate': 2.6638081860969417e-05, 'epoch': 1.95}\n",
      "{'loss': 0.618, 'grad_norm': 3.005894899368286, 'learning_rate': 2.047756339173505e-05, 'epoch': 1.96}\n",
      "{'loss': 0.5955, 'grad_norm': 3.295198917388916, 'learning_rate': 1.4317044922500678e-05, 'epoch': 1.97}\n",
      "{'loss': 0.6176, 'grad_norm': 1.9749666452407837, 'learning_rate': 8.156526453266307e-06, 'epoch': 1.98}\n",
      "{'loss': 0.6203, 'grad_norm': 1.9514583349227905, 'learning_rate': 1.996007984031936e-06, 'epoch': 2.0}\n",
      "{'train_runtime': 28516.1937, 'train_samples_per_second': 5.762, 'train_steps_per_second': 2.881, 'train_loss': 0.8985924755469817, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=82162, training_loss=0.8985924755469817, metrics={'train_runtime': 28516.1937, 'train_samples_per_second': 5.762, 'train_steps_per_second': 2.881, 'total_flos': 4.916714880054067e+17, 'train_loss': 0.8985924755469817, 'epoch': 2.0})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_preprocess(example, max_length=512):\n",
    "    zeroshot = example['input'].rsplit(\"\\n\\n\", maxsplit=1)[-1]\n",
    "    return tokenizer(zeroshot,\n",
    "                     truncation=True,\n",
    "                     padding=\"max_length\",\n",
    "                     max_length=max_length,\n",
    "                     return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33fa42b732954938b98707474367a867",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20547 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "testset = load_dataset(\"AdaptLLM/finance-tasks\", dataset_id, split=\"test\").map(eval_preprocess, batched=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = Path(rf\"D:/models/basic-Llama-3_2-LoRA-{dataset_id}\") / \"checkpoint-best\"\n",
    "best_model = PeftModel.from_pretrained(base_model, ckpt_path, torch_dtype=\"float16\").eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred: np.ndarray) -> dict[str, float]:\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=1)\n",
    "    \n",
    "    accuracy_val = accuracy_metric.compute(predictions=predictions, references=labels)['accuracy']\n",
    "    f1_val = f1_metric.compute(predictions=predictions, references=labels, average=\"weighted\")['f1']\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy_val,\n",
    "        \"f1\": f1_val,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4.54:  16%|█▌        | 3303/20547 [06:58<36:24,  7.90it/s]   \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m attn_mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(example[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     18\u001b[0m gen_idx \u001b[38;5;241m=\u001b[39m attn_mask\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mlong() \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 20\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mbase_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m logits \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mlogits\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[0;32m     23\u001b[0m gen_logits \u001b[38;5;241m=\u001b[39m logits[torch\u001b[38;5;241m.\u001b[39marange(logits\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)), gen_idx, :] \u001b[38;5;66;03m# (B, C)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\samba\\OneDrive - Durham University\\L4\\Project\\code\\venv\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:1190\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[1;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, num_logits_to_keep, **loss_kwargs)\u001b[0m\n\u001b[0;32m   1187\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m   1189\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[1;32m-> 1190\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1191\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1193\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1194\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1195\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1196\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1197\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1198\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1201\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1203\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpretraining_tp \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\samba\\OneDrive - Durham University\\L4\\Project\\code\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\samba\\OneDrive - Durham University\\L4\\Project\\code\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\samba\\OneDrive - Durham University\\L4\\Project\\code\\venv\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:945\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[1;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[0;32m    933\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    934\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m    935\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    942\u001b[0m         position_embeddings,\n\u001b[0;32m    943\u001b[0m     )\n\u001b[0;32m    944\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 945\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    946\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    947\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    948\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    949\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    950\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    951\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    952\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    953\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    954\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    956\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    958\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32mc:\\Users\\samba\\OneDrive - Durham University\\L4\\Project\\code\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\samba\\OneDrive - Durham University\\L4\\Project\\code\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\samba\\OneDrive - Durham University\\L4\\Project\\code\\venv\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:691\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[0;32m    689\u001b[0m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n\u001b[0;32m    690\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m--> 691\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost_attention_layernorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    692\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp(hidden_states)\n\u001b[0;32m    693\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n",
      "File \u001b[1;32mc:\\Users\\samba\\OneDrive - Durham University\\L4\\Project\\code\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\samba\\OneDrive - Durham University\\L4\\Project\\code\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\samba\\OneDrive - Durham University\\L4\\Project\\code\\venv\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:71\u001b[0m, in \u001b[0;36mLlamaRMSNorm.forward\u001b[1;34m(self, hidden_states)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states):\n\u001b[0;32m     70\u001b[0m     input_dtype \u001b[38;5;241m=\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m---> 71\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     72\u001b[0m     variance \u001b[38;5;241m=\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39mpow(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     73\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m hidden_states \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mrsqrt(variance \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvariance_epsilon)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tok_options = {\n",
    "    \"FPB\": [59794, 45003, 51957],    # \" Neutral\", \" Positive\", \" Negative\"\n",
    "    \"Headline\": [7566, 2360],        # \" Yes\", \" No\"\n",
    "    \"FiQA_SA\": [59794, 45003, 51957] # \" Neutral\", \" Positive\", \" Negative\"\n",
    "}\n",
    "\n",
    "base_model = LlamaForCausalLM.from_pretrained(model_id, torch_dtype=\"float16\").to(device).eval()\n",
    "\n",
    "guidance = False\n",
    "tok_opts = tok_options[dataset_id]\n",
    "\n",
    "correct = 0\n",
    "\n",
    "prog_bar = tqdm(testset)\n",
    "for i, example in enumerate(prog_bar):\n",
    "    input_ids = torch.tensor(example[\"input_ids\"], device=device)\n",
    "    attn_mask = torch.tensor(example[\"attention_mask\"])\n",
    "    gen_idx = attn_mask.sum(dim=1).long() - 1\n",
    "\n",
    "    out = base_model.forward(input_ids=input_ids, attention_mask=attn_mask.to(device))\n",
    "    logits = out.logits.cpu()\n",
    "    \n",
    "    gen_logits = logits[torch.arange(logits.size(0)), gen_idx, :] # (B, C)\n",
    "    if guidance:\n",
    "        subset = gen_logits[0, tok_opts]\n",
    "        local_argmax = torch.argmax(subset).item()\n",
    "        gen_tokens = tok_opts[local_argmax]\n",
    "    else:\n",
    "        gen_tokens = torch.argmax(gen_logits, dim=-1)\n",
    "\n",
    "    gen_raw = tokenizer.decode(gen_tokens).strip(\" \")\n",
    "    if example[\"options\"][example[\"gold_index\"]] == gen_raw:\n",
    "        correct += 1\n",
    "\n",
    "    prog_bar.set_description(f\"{100 * correct / (i+1):.2f}\")\n",
    "\n",
    "perc = correct / len(testset)\n",
    "print(f\"Accuracy {perc*100:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
