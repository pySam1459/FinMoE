{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41900d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "from pathlib import Path\n",
    "from huggingface_hub import constants as hub_c\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from evals import load_eval_dataset, get_tensors\n",
    "from FinMoE import FinMoE\n",
    "from utils import get_dataset_args\n",
    "\n",
    "assert torch.cuda.is_available(), \"CUDA not available\"\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "model_id = \"meta-llama/Llama-3.2-1B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "args = get_dataset_args(tokenizer, Path(hub_c.HF_HUB_CACHE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17440333",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = Path(r\"D:/models/FinMoE-final-top3-fast/checkpoint-3590\") # 3590  e256\n",
    "finMoE_model = FinMoE.load_pretrained(ckpt_path).to(device).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde3b5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sentence: str, dataset_id: str):\n",
    "    prompt = args.prompt_templates[dataset_id].format(sentence)\n",
    "    tokenized = tokenizer(prompt, truncation=False, return_tensors=\"pt\")\n",
    "\n",
    "    token_opts = args.token_opts[dataset_id]\n",
    "\n",
    "    output = finMoE_model.forward(tokenized[\"input_ids\"].to(device),\n",
    "                                attention_mask=tokenized[\"attention_mask\"].to(device))\n",
    "\n",
    "    out_token = torch.argmax(output.logits[0, -1, token_opts].cpu(), dim=-1)\n",
    "    return tokenizer.decode([token_opts[out_token.item()]]).strip()\n",
    "\n",
    "def display(sample):\n",
    "    text = tokenizer.decode(sample[\"input_ids\"], skip_special_tokens=True)\n",
    "    print(f\"Sample: {text}\\nPrediction: {sample[\"prediction\"]}\\nLabel: {sample[\"label\"]}\")\n",
    "\n",
    "    ## for topics\n",
    "    # text = text.split(\"0 - Analyst Update\", maxsplit=1)[0]\n",
    "    # pred = args.topics[int(sample[\"prediction\"])]\n",
    "    # label = args.topics[int(sample[\"label\"])]\n",
    "    # print(f\"Sample: {text}\\nPrediction: {pred}\\nLabel: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42aa755",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_id = \"Topics\"\n",
    "\n",
    "token_opts = args.token_opts[dataset_id]\n",
    "testset = load_eval_dataset(tokenizer, dataset_id, args)\n",
    "\n",
    "correct_dataset = [] # (Yes, No)\n",
    "wrong_dataset = []\n",
    "\n",
    "for sample in tqdm(testset):\n",
    "    input_ids, attn_mask = get_tensors(sample)\n",
    "    gen_idx = attn_mask.sum(dim=1).long() - 1\n",
    "\n",
    "    input_ids = input_ids.to(device)\n",
    "    attn_mask = attn_mask.to(device)\n",
    "\n",
    "    finMoE_model.expert.disable_adapter()\n",
    "    gate_scores = finMoE_model.gate.forward(input_ids, attn_mask)\n",
    "    expert_idx = torch.argmax(gate_scores, dim=-1).item()\n",
    "\n",
    "    finMoE_model.expert.set_adapter(f\"{expert_idx}\")\n",
    "    output = finMoE_model.expert.forward(input_ids, attn_mask)\n",
    "\n",
    "    gen_logits = output.logits[0, gen_idx, token_opts].cpu()\n",
    "    local_argmax = torch.argmax(gen_logits, dim=-1).item()\n",
    "    gen_token = token_opts[local_argmax]\n",
    "\n",
    "    sample[\"prediction\"] = tokenizer.decode(gen_token).strip(\" \")\n",
    "    sample[\"label\"] = sample[\"options\"][sample[\"gold_index\"]]\n",
    "    if len(sample[\"input_ids\"]) < 64 or True:\n",
    "        if sample[\"prediction\"] == sample[\"label\"]:\n",
    "            correct_dataset.append(sample)\n",
    "        else:\n",
    "            wrong_dataset.append(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f49120b",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_sample = random.sample(correct_dataset, k=1)\n",
    "wrong_sample = random.sample(wrong_dataset, k=1)\n",
    "\n",
    "display(correct_sample[0])\n",
    "display(wrong_sample[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
